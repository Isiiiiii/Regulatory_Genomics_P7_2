{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook you can use the flash2_pedro conda environment. Please do not install any package here. The best is if you can clone this environment ot a new one, or install the required packages in a new environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader example to fetch a batch of sequences together with their alelle frequencies per position and nucleotide and a mask which masks the positions where the allele frequencies are not high enough quality (based on the number of individuals with data at those positions)\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9504816c50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This codes takes a data frame with varinat information and fetches the sequence around the variant from a fasta file. It fetches a window with the same length as the context length of the model.\n",
    "#In some rare cases that window will surpass the boundaries of a chromosome (when the variant is close to the end of a chromosome). In that case, the variant is discarded (for now).\n",
    "import pandas as pd\n",
    "import pyranges as pr\n",
    "import math \n",
    "from pathlib import Path\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Chromosome     Start       End Strand  \\\n",
      "0           chr1     63564     65567      +   \n",
      "1           chr1    922431    924434      +   \n",
      "2           chr1    923941    925944      +   \n",
      "3           chr1    958693    960696      +   \n",
      "4           chr1    964531    966534      +   \n",
      "...          ...       ...       ...    ...   \n",
      "30055      chr22  50577912  50579915      -   \n",
      "30056      chr22  50582778  50584781      -   \n",
      "30057      chr22  50627776  50629779      -   \n",
      "30058      chr22  50627369  50629372      -   \n",
      "30059      chr22  50782291  50784294      -   \n",
      "\n",
      "                                                     seq  seq_len  \n",
      "0      TATCGATGGGCACCTTCTTTTTCTTAATTGTATCATACATTTTTAT...     2003  \n",
      "1      AGAAGACACAGACTTCAGGAGAGGAAGGCACAGGAACTCACTGGCA...     2003  \n",
      "2      TCCCCGCCGGGCGGGCGCGCGCCAGTGGACGCGGGTGCACGACTGA...     2003  \n",
      "3      TCGGGAAGAGATTTTTGCACAACTCACCAACATACGCTCCCTGCCT...     2003  \n",
      "4      TCCGCAGTGGGGCTGCGGGGAGGGGGGCGCGGGTCCGCAGTGGGGC...     2003  \n",
      "...                                                  ...      ...  \n",
      "30055  GTCTGGAAGGAATGGCCGGAAAGGATGTTACCTGGGAAATACTCCA...     2003  \n",
      "30056  ATGATGCTTCAGGGCTCCTGGAAACAGTGTCAGCTCAGATCCTGTA...     2003  \n",
      "30057  GACTTTAGTTATCCTACCGACTGCACCAAAACTGTAGGAGCCTAGA...     2003  \n",
      "30058  ACTGTTACTCTTCCCAGATCAGGCAAGGAGGGCCTCAGAGGAGGCC...     2003  \n",
      "30059  TTTGGCACATGTCAAGACCTCCTGAGGCTGTGTCACGGGCGTGCGT...     2003  \n",
      "\n",
      "[30060 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#this is the starting dataset:  contains the sequences for the upstream regions anchored at the start codon for each human gene. The sequence length is equal to the SpeciesLM input context length=2003.\n",
    "#This dataset discards the sex chromosmomes and the mitochondrial chromosome.\n",
    "seqs_df = pd.read_csv('/s/project/ml4rg_students/2025/project07/data/gtf_start_extended_ints_df_2003_seq.csv')\n",
    "print (seqs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gnomad_db.database import gnomAD_DB\n",
    "\n",
    "database_location = '/s/project/benchmark-lm/ssd-cache'\n",
    "db = gnomAD_DB(database_location, gnomad_version=\"v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuc_to_int_dict = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "revcomp_dict = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'}\n",
    "\n",
    "def one_hot_seq(seq):\n",
    "    \n",
    "    seq = seq.upper()\n",
    "    one_hot = np.zeros((len(seq), 4), dtype=int)\n",
    "    for i, nucleotide in enumerate(seq):\n",
    "        if nucleotide == 'A':\n",
    "            one_hot[i, 0] = 1\n",
    "        elif nucleotide == 'C':\n",
    "            one_hot[i, 1] = 1\n",
    "        elif nucleotide == 'G':\n",
    "            one_hot[i, 2] = 1\n",
    "        elif nucleotide == 'T':\n",
    "            one_hot[i, 3] = 1\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown nucleotide {nucleotide} at position {i} in sequence {seq}\")\n",
    "    return one_hot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_af_from_interval(interval):\n",
    "\n",
    "    df_region = db.get_info_for_interval(chrom=interval['Chromosome'].values[0].strip('chr'), \n",
    "        interval_start=interval['Start'].values[0] + 1, #IMPORTANT 1 BASED COORDINATES IN GnomAD\n",
    "        interval_end=interval['End'].values[0], query=\"*\") #END IS INCLUDED\n",
    "\n",
    "    #only consider SNPs that Pass the gnomad filtering criteria\n",
    "    df_region = df_region[df_region['filter'] == 'PASS'].copy()\n",
    "    df_region['len_ref'] = df_region['ref'].apply(len)\n",
    "    df_region['len_alt'] = df_region['alt'].apply(len)\n",
    "    df_region = df_region[(df_region['len_ref'] == 1) & (df_region['len_alt'] == 1)].copy().reset_index(drop=True)\n",
    "\n",
    "    if interval['Strand'].values[0] == '+':\n",
    "        df_region['relative_pos'] = (df_region['pos'] - (interval['Start'].values[0] + 1)).astype(int)  # this is zero based\n",
    "\n",
    "        df_region['ref_int'] = df_region['ref'].map(nuc_to_int_dict).astype(int)\n",
    "        df_region['alt_int'] = df_region['alt'].map(nuc_to_int_dict).astype(int)\n",
    "\n",
    "        interval_length = interval['End'].values[0] - interval['Start'].values[0]\n",
    "        afs_arr = np.zeros((interval_length, 4))\n",
    "        afs_arr[df_region['relative_pos'].values, df_region['alt_int'].values] = df_region['AF'].values\n",
    "\n",
    "        one_hot_arr = one_hot_seq(interval['seq'].values[0])\n",
    "\n",
    "        afs_arr[one_hot_arr==1] = 1 - afs_arr.sum(axis=-1)\n",
    "\n",
    "    elif interval['Strand'].values[0] == '-':\n",
    "        df_region['relative_pos'] = (interval['End'].values[0] - df_region['pos']).astype(int)\n",
    "\n",
    "        df_region['ref_int'] = df_region['ref'].map(revcomp_dict).map(nuc_to_int_dict).astype(int)\n",
    "        df_region['alt_int'] = df_region['alt'].map(revcomp_dict).map(nuc_to_int_dict).astype(int)\n",
    "\n",
    "        interval_length = interval['End'].values[0] - interval['Start'].values[0]\n",
    "        afs_arr = np.zeros((interval_length, 4))\n",
    "        afs_arr[df_region['relative_pos'].values, df_region['alt_int'].values] = df_region['AF'].values\n",
    "\n",
    "        one_hot_arr = one_hot_seq(interval['seq'].values[0])\n",
    "        afs_arr[one_hot_arr==1] = 1 - afs_arr.sum(axis=-1)\n",
    "\n",
    "    return afs_arr, df_region "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch total allele number per position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "Permission denied (os error 13): /s/project/benchmark-lm/data/gnomad4_1_allele_number/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/modules/i12g/anaconda/envs/ml4rg25_g7_1/lib/python3.10/site-packages/polars/lazyframe/frame.py:776\u001b[0m, in \u001b[0;36mLazyFrame._repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 776\u001b[0m     dot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    777\u001b[0m     svg \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mcheck_output(\n\u001b[1;32m    778\u001b[0m         [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdot\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-Nshape=box\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-Tsvg\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mencode()\n\u001b[1;32m    779\u001b[0m     )\n",
      "\u001b[0;31mPermissionError\u001b[0m: Permission denied (os error 13): /s/project/benchmark-lm/data/gnomad4_1_allele_number/",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/modules/i12g/anaconda/envs/ml4rg25_g7_1/lib/python3.10/site-packages/IPython/core/formatters.py:406\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    404\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/modules/i12g/anaconda/envs/ml4rg25_g7_1/lib/python3.10/site-packages/polars/lazyframe/frame.py:785\u001b[0m, in \u001b[0;36mLazyFrame._repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    781\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<h4>NAIVE QUERY PLAN</h4><p>run <b>LazyFrame.show_graph()</b> to see\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    782\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the optimized version</p>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msvg\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    783\u001b[0m             )\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m--> 785\u001b[0m             insert \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<p></p>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    787\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;124m<i>naive plan: (run <b>LazyFrame.explain(optimized=True)</b> to see the optimized plan)</i>\u001b[39m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;124m    <p></p>\u001b[39m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;124m    <div>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minsert\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</div>\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[0;32m/opt/modules/i12g/anaconda/envs/ml4rg25_g7_1/lib/python3.10/site-packages/polars/_utils/deprecation.py:97\u001b[0m, in \u001b[0;36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min-memory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstreaming\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/modules/i12g/anaconda/envs/ml4rg25_g7_1/lib/python3.10/site-packages/polars/lazyframe/opt_flags.py:330\u001b[0m, in \u001b[0;36mforward_old_opt_flags.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m         optflags \u001b[38;5;241m=\u001b[39m cb(optflags, kwargs\u001b[38;5;241m.\u001b[39mpop(key))  \u001b[38;5;66;03m# type: ignore[no-untyped-call,unused-ignore]\u001b[39;00m\n\u001b[1;32m    329\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizations\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m optflags\n\u001b[0;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/modules/i12g/anaconda/envs/ml4rg25_g7_1/lib/python3.10/site-packages/polars/lazyframe/frame.py:1301\u001b[0m, in \u001b[0;36mLazyFrame.explain\u001b[0;34m(self, format, optimized, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, streaming, engine, tree_format, optimizations)\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ldf\u001b[38;5;241m.\u001b[39mdescribe_plan_tree()\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribe_plan\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mPermissionError\u001b[0m: Permission denied (os error 13): /s/project/benchmark-lm/data/gnomad4_1_allele_number/"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<LazyFrame at 0x7F9514833DF0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "scores_lazy = pl.scan_parquet(\n",
    "    \"/s/project/benchmark-lm/data/gnomad4_1_allele_number/\"\n",
    ")\n",
    "scores_lazy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer - SpeciesLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type rotarybert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.amp import autocast\n",
    "import tqdm\n",
    "\n",
    "# Load the model\n",
    "model_name = \"johahi/specieslm-metazoa-upstream-k6\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# Load the corresponding tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_species = 'homo_sapiens'\n",
    "assert proxy_species in tokenizer.get_vocab()\n",
    "\n",
    "def kmers(seq, k=6): #for codons, k = 6\n",
    "    # splits a sequence into non-overlappnig k-mers\n",
    "    return [seq[i:i + k] for i in range(0, len(seq), k) if i + k <= len(seq)]\n",
    "\n",
    "def kmers_stride1(seq, k=6):\n",
    "    # splits a sequence into overlapping k-mers\n",
    "    return [seq[i:i + k] for i in range(0, len(seq)-k+1)]  \n",
    "\n",
    "def tok_func_species(seq, proxy_species):\n",
    "    res = tokenizer(proxy_species + \" \" +  \" \".join(kmers_stride1(seq)))\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pytorch dataset which inputs the seqs_df and ilocs it to get the interval and the afs_arr and an_arr\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GnomADIntervalSpeciesLMDataset(Dataset):\n",
    "    def __init__(self, seqs_df, minimum_total_allele_number=150788):\n",
    "        self.seqs_df = seqs_df\n",
    "        self.minimum_total_allele_number = minimum_total_allele_number # 99% of positions in the human genome are above this. Meaning for 99% of positions we have data on minimum_total_allele_number/2 or more individuals (/2 because each human has 2 sets of chromosome from the father and mother)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.seqs_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        interval = self.seqs_df.iloc[idx].to_frame().T\n",
    "        afs_arr, _ = get_af_from_interval(interval)\n",
    "        an_df = scores_lazy.filter((pl.col(\"chrom\") == interval['Chromosome'].values[0]) & (pl.col(\"pos\") >= interval['Start'].values[0]+1) & (pl.col(\"pos\") <= interval['End'].values[0])).collect().to_pandas()\n",
    "        an_arr = an_df['AN'].values if interval['Strand'].values[0] == '+' else an_df['AN'].values[::-1]\n",
    "        an_mask = an_arr < self.minimum_total_allele_number\n",
    "        input_ids = tok_func_species(interval['seq'].values[0], proxy_species=proxy_species)['input_ids']\n",
    "        \n",
    "        \n",
    "        return {\n",
    "            'labels': torch.tensor(afs_arr.copy(), dtype=torch.float32),\n",
    "            'an_arr': torch.tensor(an_arr.copy(), dtype=torch.long),\n",
    "            'an_mask': torch.tensor(an_mask.copy(), dtype=torch.bool), #True if the position does not pass the quality criteria of the minimum_total_allele_number\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "gnomad_dataset = GnomADIntervalSpeciesLMDataset(seqs_df)\n",
    "\n",
    "loader  = DataLoader(\n",
    "    gnomad_dataset,\n",
    "    batch_size = 8,\n",
    "    shuffle    = True,\n",
    "    num_workers= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/modules/i12g/anaconda/envs/ml4rg25_g7_1/lib/python3.10/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m/opt/modules/i12g/anaconda/envs/ml4rg25_g7_1/lib/python3.10/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/modules/i12g/anaconda/envs/ml4rg25_g7_1/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/modules/i12g/anaconda/envs/ml4rg25_g7_1/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m, in \u001b[0;36mGnomADIntervalSpeciesLMDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     15\u001b[0m     interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseqs_df\u001b[38;5;241m.\u001b[39miloc[idx]\u001b[38;5;241m.\u001b[39mto_frame()\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m---> 16\u001b[0m     afs_arr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mget_af_from_interval\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     an_df \u001b[38;5;241m=\u001b[39m scores_lazy\u001b[38;5;241m.\u001b[39mfilter((pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchrom\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m interval[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChromosome\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m&\u001b[39m (pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m interval[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m interval[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnd\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]))\u001b[38;5;241m.\u001b[39mcollect()\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[1;32m     18\u001b[0m     an_arr \u001b[38;5;241m=\u001b[39m an_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAN\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mif\u001b[39;00m interval[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrand\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m an_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAN\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m, in \u001b[0;36mget_af_from_interval\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_af_from_interval\u001b[39m(interval):\n\u001b[0;32m----> 3\u001b[0m     df_region \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[38;5;241m.\u001b[39mget_info_for_interval(chrom\u001b[38;5;241m=\u001b[39minterval[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChromosome\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchr\u001b[39m\u001b[38;5;124m'\u001b[39m), \n\u001b[1;32m      4\u001b[0m         interval_start\u001b[38;5;241m=\u001b[39minterval[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m#IMPORTANT 1 BASED COORDINATES IN GnomAD\u001b[39;00m\n\u001b[1;32m      5\u001b[0m         interval_end\u001b[38;5;241m=\u001b[39minterval[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnd\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m], query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m#END IS INCLUDED\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#only consider SNPs that Pass the gnomad filtering criteria\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     df_region \u001b[38;5;241m=\u001b[39m df_region[df_region[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPASS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbatch\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future steps:\n",
    "- You have now seen how to run each DNA LM: SpeciesLM and GPN-MSA, and how to fetch the allele frequencies and counts for a specific region. \n",
    "- Your next goal will be to fine-tune each model on the allele frequency per position in the genome.\n",
    "- Most positions do not have variants, there the allele frequency for variant nucleotides is 0 and the reference nucleotide is 1\n",
    "- Start by creating a train/validation/test split for the dataset. \n",
    "- Allele frequencies are shaped by mutation biases, unrelated to fitness effects, you can decide whether to correct for this when training the model or afterwards\n",
    "  - using the mutation probabilities estimated by the neutral mutation rate model as another feature or in the loss function. This way you provide what to expect under no selection pressure and the model can focus on the selection/fitness effects\n",
    "  - correcting the predicted allele frequencies by the estimated mutation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda-ml4rg_p7_2]",
   "language": "python",
   "name": "conda-env-anaconda-ml4rg_p7_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
